{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision as tv\n",
    "from torch.autograd import Variable\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 显示中文标签\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "\n",
    "noiseSize = 100     # 噪声维度\n",
    "n_generator_feature = 64        # 生成器feature map数\n",
    "n_discriminator_feature = 64        # 判别器feature map数\n",
    "batch_size = 256\n",
    "d_every = 1     # 每一个batch训练一次discriminator\n",
    "g_every = 5     # 每五个batch训练一次generator\n",
    "\n",
    "class NetGenerator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetGenerator,self).__init__()\n",
    "        self.main = nn.Sequential(      # 神经网络模块将按照在传入构造器的顺序依次被添加到计算图中执行\n",
    "            nn.ConvTranspose2d(noiseSize, n_generator_feature * 8, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(n_generator_feature * 8),\n",
    "            nn.ReLU(True),       # (n_generator_feature * 8) × 4 × 4        (1-1)*1+1*(4-1)+0+1 = 4\n",
    "            nn.ConvTranspose2d(n_generator_feature * 8, n_generator_feature * 4, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(n_generator_feature * 4),\n",
    "            nn.ReLU(True),      # (n_generator_feature * 4) × 8 × 8     (4-1)*2-2*1+1*(4-1)+0+1 = 8\n",
    "            nn.ConvTranspose2d(n_generator_feature * 4, n_generator_feature * 2, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(n_generator_feature * 2),\n",
    "            nn.ReLU(True),  # (n_generator_feature * 2) × 16 × 16\n",
    "            nn.ConvTranspose2d(n_generator_feature * 2, n_generator_feature, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(n_generator_feature),\n",
    "            nn.ReLU(True),      # (n_generator_feature) × 32 × 32\n",
    "            nn.ConvTranspose2d(n_generator_feature, 3, kernel_size=5, stride=3, padding=1, bias=False),\n",
    "            nn.Tanh()       # 3 * 96 * 96\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "\n",
    "class NetDiscriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetDiscriminator,self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(3, n_discriminator_feature, kernel_size=5, stride=3, padding=1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),        # n_discriminator_feature * 32 * 32\n",
    "            nn.Conv2d(n_discriminator_feature, n_discriminator_feature * 2, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(n_discriminator_feature * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),         # (n_discriminator_feature*2) * 16 * 16\n",
    "            nn.Conv2d(n_discriminator_feature * 2, n_discriminator_feature * 4, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(n_discriminator_feature * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),  # (n_discriminator_feature*4) * 8 * 8\n",
    "            nn.Conv2d(n_discriminator_feature * 4, n_discriminator_feature * 8, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(n_discriminator_feature * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),  # (n_discriminator_feature*8) * 4 * 4\n",
    "            nn.Conv2d(n_discriminator_feature * 8, 1, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "            nn.Sigmoid()        # 输出一个概率\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input).view(-1)\n",
    "\n",
    "\n",
    "def train():\n",
    "    for i, (image,_) in tqdm.tqdm(enumerate(dataloader)):       # type((image,_)) = <class 'list'>, len((image,_)) = 2 * 256 * 3 * 96 * 96\n",
    "        real_image = Variable(image).to(device)\n",
    "\n",
    "        if (i + 1) % d_every == 0:\n",
    "            optimizer_d.zero_grad()\n",
    "            output = Discriminator(real_image)      # 尽可能把真图片判为True\n",
    "            error_d_real = criterion(output, true_labels)\n",
    "            error_d_real.backward()\n",
    "\n",
    "            noises.data.copy_(torch.randn(batch_size, noiseSize, 1, 1)).to(device)\n",
    "            fake_img = Generator(noises).detach()       # 根据噪声生成假图\n",
    "            fake_output = Discriminator(fake_img)       # 尽可能把假图片判为False\n",
    "            error_d_fake = criterion(fake_output, fake_labels)\n",
    "            error_d_fake.backward()\n",
    "            optimizer_d.step()\n",
    "\n",
    "        if (i + 1) % g_every == 0:\n",
    "            optimizer_g.zero_grad()\n",
    "            noises.data.copy_(torch.randn(batch_size, noiseSize, 1, 1)).to(device)\n",
    "            fake_img = Generator(noises)        # 这里没有detach\n",
    "            fake_output = Discriminator(fake_img)       # 尽可能让Discriminator把假图片判为True\n",
    "            error_g = criterion(fake_output, true_labels)\n",
    "            error_g.backward()\n",
    "            optimizer_g.step()\n",
    "\n",
    "\n",
    "def show(num):\n",
    "    fix_fake_imags = Generator(fix_noises)\n",
    "    fix_fake_imags = fix_fake_imags.data.cpu()[:64] * 0.5 + 0.5\n",
    "\n",
    "    # x = torch.rand(64, 3, 96, 96)\n",
    "    fig = plt.figure(1)\n",
    "\n",
    "    i = 1\n",
    "    for image in fix_fake_imags:\n",
    "        ax = fig.add_subplot(8, 8, eval('%d' % i))\n",
    "        # plt.xticks([]), plt.yticks([])  # 去除坐标轴\n",
    "        plt.axis('off')\n",
    "        plt.imshow(image.permute(1, 2, 0))\n",
    "        i += 1\n",
    "    plt.subplots_adjust(left=None,  # the left side of the subplots of the figure\n",
    "                        right=None,  # the right side of the subplots of the figure\n",
    "                        bottom=None,  # the bottom of the subplots of the figure\n",
    "                        top=None,  # the top of the subplots of the figure\n",
    "                        wspace=0.05,  # the amount of width reserved for blank space between subplots\n",
    "                        hspace=0.05)  # the amount of height reserved for white space between subplots)\n",
    "    print('第%d迭代结果' % num )\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "dir = './faces'\n",
    "if __name__ == '__main__':\n",
    "    transform = tv.transforms.Compose([\n",
    "        tv.transforms.Resize(96),     # 图片尺寸, transforms.Scale transform is deprecated\n",
    "        tv.transforms.CenterCrop(96),\n",
    "        tv.transforms.ToTensor(),\n",
    "        tv.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))       # 变成[-1,1]的数\n",
    "    ])\n",
    "\n",
    "    dataset = tv.datasets.ImageFolder(dir, transform=transform)\n",
    "\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4, drop_last=True)   # module 'torch.utils.data' has no attribute 'DataLoder'\n",
    "\n",
    "    print('数据加载完毕！')\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print('Using device:', device)\n",
    "    \n",
    "    # 定义生成器和判别器，并转移到GPU\n",
    "    Generator = NetGenerator().to(device)\n",
    "    Discriminator = NetDiscriminator().to(device)\n",
    "    # Generator = NetGenerator()\n",
    "    # Discriminator = NetDiscriminator()\n",
    "    # 优化器和损失函数不需要转移到GPU\n",
    "    \n",
    "    # 标签变量和噪声变量也需要转移到GPU\n",
    "    true_labels = Variable(torch.ones(batch_size)).to(device)\n",
    "    fake_labels = Variable(torch.zeros(batch_size)).to(device)\n",
    "    fix_noises = Variable(torch.randn(batch_size, noiseSize, 1, 1)).to(device)\n",
    "    noises = Variable(torch.randn(batch_size, noiseSize, 1, 1)).to(device)\n",
    "\n",
    "    optimizer_g = torch.optim.Adam(Generator.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "    optimizer_d = torch.optim.Adam(Discriminator.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "    criterion = torch.nn.BCELoss()\n",
    "\n",
    "    # true_labels = Variable(torch.ones(batch_size))     # batch_size\n",
    "    # fake_labels = Variable(torch.zeros(batch_size))\n",
    "    # fix_noises = Variable(torch.randn(batch_size, noiseSize, 1, 1))\n",
    "    # noises = Variable(torch.randn(batch_size, noiseSize, 1, 1))     # 均值为0，方差为1的正态分布\n",
    "\n",
    "    if torch.cuda.is_available() == True:\n",
    "        print('Cuda is available!')\n",
    "\n",
    "    plot_epoch = [1,5,10,20,50,100,199]\n",
    "\n",
    "    for i in range(200):        # 最大迭代次数\n",
    "        train()\n",
    "        print('迭代次数：{}'.format(i))\n",
    "        if i in plot_epoch:\n",
    "            show(i)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
