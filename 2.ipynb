{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b3e0a72",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "### 作业二\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ece50dcd",
   "metadata": {},
   "source": [
    "1. 在`linear-regression-concise.ipynb`或`softmax-regression-concise.ipynb`中例子的基础,如果我们将权重初始化为零，会发生什么。算法仍然有效吗？试分析原因。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9016a0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.init.zeros_() 将权重初始化为0后发生错误：TypeError: zeros_() missing 1 required positional argument: 'tensor', 算法无效。\n",
    "# 原因是在现有的代码中，net.apply(init_weights) 将会应用 init_weights 函数到网络中的每一层。然而，由于 nn.init.zeros_() 没有传递任何参数，它不会初始化任何权重。\n",
    "# 相反，它会尝试将所有的权重参数初始化为零，但是由于它没有接收到任何参数，它将会引发一个错误。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b2606d91",
   "metadata": {},
   "source": [
    "2. 在`linear-regression-concise.ipynb`或`softmax-regression-concise.ipynb`中例子的基础上, 尝试调整超参数，例如批量大小、迭代周期数和学习率，观察损失函数值下降的快慢。试分析原因。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d6974eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 当学习率较大时，损失函数可能会出现震荡或不稳定的情况；而当学习率较小时，损失函数的收敛速度会变慢，需要更多的迭代周期才能达到较低的损失值。\n",
    "# 当迭代周期数较少时，模型可能无法充分学习数据的特征，导致欠拟合；而当迭代周期数较多时，模型可能会过度拟合训练数据，表现在训练集上表现良好但在测试集上泛化能力较差。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0491b3fb",
   "metadata": {},
   "source": [
    "3. 如果样本个数不能被批量大小整除，`linear-regression-scratch.ipynb`中`data_iter`函数的行为会有什么变化？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "073ee100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果样本个数不能被批量大小整除，最后一个批次的大小将小于指定的批量大小。\n",
    "# 具体来说，如果样本个数不能被批量大小整除，最后一个批次将包含剩余的样本，其大小将小于指定的批量大小。这意味着在最后一个批次中，features 和 labels 的大小将不再匹配指定的批量大小。\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "512996f2",
   "metadata": {},
   "source": [
    "4. 用Huber损失代替Fsion-Mnist分类中的原损失函数MSE，即\n",
    "    $$l(y,y') = \\begin{cases}|y-y'| -\\frac{\\sigma}{2} & \\text{ if } |y-y'| > \\sigma \\\\ \\frac{1}{2 \\sigma} (y-y')^2 & \\text{ 其它情况}\\end{cases}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84d288be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def huber_loss(y_hat,y,delta = 1.0):\n",
    "    \"\"\"Huber损失\"\"\"\n",
    "    residual = y_hat - y.reshape(y_hat.shape)\n",
    "    huber_term = torch.where(torch.abs(residual) < delta, 0.5 * residual ** 2, delta * (torch.abs(residual) - 0.5 * delta))\n",
    "    return huber_term\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b3aa6ffe",
   "metadata": {},
   "source": [
    "5. 在`mlp-concise.ipynb`例子的基础上,(1)尝试添加不同数量的隐藏层（也可以修改学习率），怎么样设置效果最好？(2)尝试不同的激活函数，哪个效果最好？(3)尝试不同的方案来初始化权重，什么方法效果最好？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "683028a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m         nn\u001b[38;5;241m.\u001b[39minit\u001b[38;5;241m.\u001b[39mkaiming_uniform_(m\u001b[38;5;241m.\u001b[39mweight)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# 应用Xavier初始化\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[43mnet\u001b[49m\u001b[38;5;241m.\u001b[39mapply(xavier_init_weights)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# 或者，应用He初始化\u001b[39;00m\n\u001b[0;32m     15\u001b[0m net\u001b[38;5;241m.\u001b[39mapply(he_init_weights)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'net' is not defined"
     ]
    }
   ],
   "source": [
    "#使用了Tanh激活函数\n",
    "net = nn.Sequential(nn.Flatten(),\n",
    "                    nn.Linear(784, 256),\n",
    "                    nn.Tanh(), \n",
    "                    nn.Linear(256, 256),\n",
    "                    nn.Tanh(),\n",
    "                    nn.Linear(256, 256),\n",
    "                    nn.Tanh(),\n",
    "                    nn.Linear(256, 10))\n",
    "\n",
    "# 使用Xavier初始化来初始化权重\n",
    "def xavier_init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "net.apply(xavier_init_weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "required_libs": [],
  "vscode": {
   "interpreter": {
    "hash": "50bfc351199d956b4024fbbd9aca69be4a9c56b71e449cee70b952cf93a37264"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
